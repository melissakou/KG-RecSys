{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative knowledge base embedding for recommender systems\n",
    "\n",
    "[Collaborative knowledge base embedding for recommender systems](https://www.kdd.org/kdd2016/subtopic/view/collaborative-knowledge-base-embedding-for-recommender-systems)\n",
    "\n",
    "# 1. Introduction\n",
    "\n",
    "- disadvantages of CF methods:\n",
    "    - limited performance when user-item interactions are very sparse\n",
    "    - can not recommend new items.\n",
    "\n",
    "➡️ hybrid recommender system: combine CF and auxiliary information such as item content\n",
    "\n",
    "- This paper integrate CF with item's knowledge base, included:\n",
    "    1. network structure information → network embedding approach to extract infomation\n",
    "    2. textual content → stacked denoising auto-encoders to extract information\n",
    "    3. visual content → stacked convolutional auto-encoders to extract information\n",
    "- integrate CF with items' semantic representations by their framework: \n",
    "Collaborative Knowledge Base Embedding (CKE)\n",
    "\n",
    "# 2. Preliminary\n",
    "\n",
    "## 2.1 User Implicit Feedback\n",
    "\n",
    "Assume there are $m$ users and $n$ items, we define the user implicit feedback matrix $\\bold{R} \\in \\mathbb{R}^{m \\times n}$.\n",
    "\n",
    "$R_{ij}=1,$ if user $i$ and item $j$ interactions have been observed, $0$ otherwise.\n",
    "\n",
    "## 2.2 Knowledge Base\n",
    "\n",
    "### 2.2.1 Structural knowledge\n",
    "\n",
    "heterogeneous network (KG)\n",
    "\n",
    "### 2.2.2 Textual knowledge\n",
    "\n",
    "textual knowledge, usually gives the main topics of this book or this movie.\n",
    "\n",
    "### 2.2.3 Visual knowledge\n",
    "\n",
    "images knowledge, such as book's front cover or as movie's poster image.\n",
    "\n",
    "## 2.3 Problem Formulation\n",
    "\n",
    "user-item implicit interaction + structural knowledge + textual knowledge + visual knowledge\n",
    "\n",
    "➡️ recommend each user with a ranked list of items\n",
    "\n",
    "# 3. Overview\n",
    "\n",
    "![imgs/Untitled.png](imgs/Untitled.png)\n",
    "\n",
    "CKE mainly consist of two steps:\n",
    "\n",
    "1. knowledge base embedding\n",
    "    - structural embedding: Bayesian TransR\n",
    "    - textual embedding: Bayesian stacked denoising autoencoder (Bayesian SDAE)\n",
    "    - visual embedding: Bayesian stacked convolutional autoencoder (Bayesian SCAE)\n",
    "2. collaborative joint learning\n",
    "\n",
    "# 4. Knowledge Base Embedding\n",
    "\n",
    "## 4.1 Structural Embedding\n",
    "\n",
    "- Bayesian TransR\n",
    "看起來跟TransR差不多，主要在negative sampling的時候考慮 incorrect triplet 的難易度:\n",
    "incorrect triplet $(v_h,r,v_t')$ 被抽到的機率: $\\sigma(f_r(v_h,v_t)-f_r(v_h,v_t'))$\n",
    "\n",
    "## 4.2 Textual Embedding\n",
    "\n",
    "- stacked denoising autoencoders (SDAE)\n",
    "bag-of-words vector做autoencoder\n",
    "\n",
    "## 4.3 Visual Embedding\n",
    "\n",
    "- stacked convolutional autoencoder (SCAE)\n",
    "\n",
    "# 5. Collaborative Joint Learning\n",
    "\n",
    "- item latent vector:\n",
    "$e_j = \\eta_j + v_j + X_{\\frac{L_t}{2}, j*} + Z_{\\frac{L_ㄒ}{2}, j*}$\n",
    "- pair-wise preference probability:\n",
    "$p(j>j';i|\\theta)=\\sigma(u_i^Te_j - u_i^Te_j')$\n",
    "\n",
    "## Process of CKE\n",
    "\n",
    "1. Consider structural knowledge:\n",
    "\n",
    "    (a) initialize entity embedding from $\\mathcal{N}(0, \\lambda_v^{-1}I)$\n",
    "\n",
    "    (b) initialize relation embedding from $\\mathcal{N}(0, \\lambda_r^{-1}I)$\n",
    "\n",
    "    (c) draw $(v_h, r, v_t, v_t') \\in \\mathcal{S}$ with probability $\\sigma(f_r(v_h,v_t)-f_r(v_h,v_t'))$\n",
    "\n",
    "2. Consider textual knowledge, for each layer $l$:\n",
    "\n",
    "    (a) initialize weight parameter $W_l \\sim \\mathcal{N}(0, \\lambda_W^{-1}I)$\n",
    "\n",
    "    (b) initialize bias parameter $b_l \\sim \\mathcal{N}(0, \\lambda_b^{-1}I)$\n",
    "\n",
    "    (c) add noise on output layer:  $X_l \\sim \\mathcal{N}(\\sigma(X_{l-1}W_l + b_l), \\lambda_X^{-1}I)$\n",
    "\n",
    "3. Consider visual knowledge, for each layer $l$:\n",
    "\n",
    "    (a) initialize weight parameter $Q_l \\sim \\mathcal{N}(0, \\lambda_Q^{-1}I)$\n",
    "\n",
    "    (b) initialize bias parameter $c_l \\sim \\mathcal{N}(0, \\lambda_c^{-1}I)$\n",
    "\n",
    "    (c) add noise on output layer:\n",
    "\n",
    "    - if fully connected layer:  $Z_l \\sim \\mathcal{N}(\\sigma(Z_{l-1}Q_l + c_l), \\lambda_Z^{-1}I)$\n",
    "    - if convolution layer: $Z_l \\sim \\mathcal{N}(\\sigma(Z_{l-1}*Q_l + c_l), \\lambda_Z^{-1}I)$\n",
    "4. Combine all embedding as item latent vector:\n",
    "$e_j = \\eta_j + v_j + X_{\\frac{L_t}{2}, j*} + Z_{\\frac{L_ㄒ}{2}, j*}$\n",
    "where latent item offset vector $\\eta_j \\sim \\mathcal{N}(0, \\lambda_I^{-1}I)$\n",
    "5. initialize user latent vector from $\\mathcal{N}(0, \\lambda_U^{-1}I)$\n",
    "6. For each triple $(i,j,j') \\in \\mathcal{D}$, draw from probability $\\sigma(u_i^Te_j - u_i^Te_j')$\n",
    "where $\\mathcal{D}$ is a collection of triples, where $(i,j,j')$ satisfies that $R_ij=1$ and $R_ij'=0$, $j'$ is randomly sampled from user i's uninterested items.\n",
    "\n",
    "## Learning parameters\n",
    "\n",
    "(1) user preference: $-\\sum_{(i,j,j') \\in \\mathcal{D}} ln ~ \\sigma(u_i^Te_j - u_i^Te_j')$\n",
    "\n",
    "(2) SDAE loss: $\\frac{\\lambda_X}{2} \\sum_l || \\sigma(X_{l-1}W_l+b_l) - X_l ||_2^2$\n",
    "\n",
    "(3) TransR loss: $-\\sum_{(v_h,r,v_t,v_t')}ln ~ \\sigma(|| v_hM_r + r - v_tM_r ||_2^2 - || v_hM_r + r - v_t'M_r ||_2^2)$\n",
    "\n",
    "(4) SCAE loss:\n",
    "\n",
    "$\\frac{\\lambda_z}{2} \\sum_{l \\notin \\{ \\frac{L_v}{2}, \\frac{L_v}{2}+1 \\}} || \\sigma(Z_{l-1}*Q_l+c_l) - Z_l ||_2^2 + \\frac{\\lambda_z}{2} \\sum_{l \\in \\{ \\frac{L_v}{2}, \\frac{L_v}{2}+1 \\}} || \\sigma(Z_{l-1}Q_l+c_l) - Z_l ||_2^2$\n",
    "\n",
    "(5) regularization on user embeddings: $\\frac{\\lambda_U}{2}\\sum_i || u_i ||_2^2$\n",
    "\n",
    "(6) regularization on entity embeddings: $\\frac{\\lambda_v}{2}\\sum_v ||v||_2^2$\n",
    "\n",
    "(7) regularization on SDAE weights: $\\frac{1}{2} \\sum_l (\\lambda_W ||W_l||_2^2 + \\lambda_b ||b_l||_2^2)$\n",
    "\n",
    "(8) regularization on SCAE weights: $\\frac{1}{2} \\sum_l (\\lambda_Q ||Q_l||_2^2 + \\lambda_c ||c_l||_2^2)$\n",
    "\n",
    "(9) regularization on latent item offset:\n",
    "     $\\frac{\\lambda_I}{2} \\sum_j || e_j-v_j-X_{\\frac{L_t}{2},j*}-Z_{\\frac{L_v}{2},j*} ||_2^2 = \\frac{\\lambda_I}{2} \\sum_j || \\eta_j ||_2^2$\n",
    "\n",
    "(10) regularization on relation embeddings: $\\frac{\\lambda_r}{2}\\sum_r ||r||_2^2$\n",
    "\n",
    "(11) regularization on projection matrix: $\\frac{\\lambda_M}{2} \\sum_r ||M_r ||_2^2$\n",
    "\n",
    "minimize the objective:\n",
    "\n",
    "$obj = (1)+(2)+...+(11)$\n",
    "\n",
    "- use SGD\n",
    "- In each iteration, for a randomly sampled triple $(i,j,j') \\in \\mathcal{D}$, find the subset $\\mathcal{S}_{j,j'} \\in \\mathcal{S}$ satisfying that each quadruple in $\\mathcal{S}_{j,j'}$ contain item $j$ or $j'$.\n",
    "\n",
    "## Prediction\n",
    "\n",
    "item recommendation for user $i$:\n",
    "$u_i^Te_{j1} > u_i^Te_{j2} > ... >u_i^Te_{jn}$ ➡️ $j_1 > j_2 > ... > j_n$\n",
    "\n",
    "# 6. Experiments\n",
    "\n",
    "## 6.1 Datasets Description\n",
    "\n",
    "![imgs/Untitled%201.png](imgs/Untitled%201.png)\n",
    "\n",
    "#sk nodes: total number of nodes in the structural knowledge.\n",
    "\n",
    "#sk edges: total number of edges in the structural knowledge.\n",
    "\n",
    "#sk edge types: total number of edge types in the structural knowledge.\n",
    "\n",
    "#tk items: number of items having textual knowledge.\n",
    "\n",
    "#vk items: number of items having visual knowledge.\n",
    "\n",
    "## 6.2 Evaluation Schema\n",
    "\n",
    "**metrics**\n",
    "\n",
    "- precision is not a suitable metrics for implicit feedback recommendation. [[ref](https://icml.cc/2012/papers/407.pdf)]\n",
    "- use MAP@k and Recall@k\n",
    "\n",
    "**train/test splitting**\n",
    "\n",
    "- 70% items associated with each user as Train, remaining as Test.\n",
    "- repeat 5 times bootstrap.\n",
    "- use validation set from each training set to find hyperparameters.\n",
    "\n",
    "## 6.3~6.6\n",
    "\n",
    "structural knowledge、textual knowledge、visual knowledge、CKE(whole frame work)都勝過其他方法"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
